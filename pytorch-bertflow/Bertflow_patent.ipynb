{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dbc239a-0b7d-42ff-a2db-46e71f78cddf",
   "metadata": {},
   "source": [
    "# Train a Bertflow model for sentence embedding (3 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a1e5ae3-ef56-4fc9-b8ac-3dc732798b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import AdamW\n",
    "from operator import itemgetter\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e2b69c8-a177-4ae6-8476-898a57052b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = pickle.load(open('../temp_results/mini_label2id_dict.pkl','rb'))\n",
    "id2label = pickle.load(open('../temp_results/mini_id2label_lst.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aee0f61b-0d73-4980-9dc1-02cafb9afe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/Patent14K/train.csv')\n",
    "test_data = pd.read_csv('../data/Patent14K/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7506f49c-923f-4b19-ab57-98cc5d67491c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1bcdb48b-b1ab-424d-9056-d90fb7562fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at anferico/bert-for-patents were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from tflow_utils import TransformerGlow, AdamWeightDecayOptimizer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name_or_path = 'anferico/bert-for-patents'\n",
    "bertflow = TransformerGlow(model_name_or_path, pooling='first-last-avg')  # pooling could be 'mean', 'max', 'cls' or 'first-last-avg' (mean pooling over the first and the last layers)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters= [\n",
    "    {\n",
    "        \"params\": [p for n, p in bertflow.glow.named_parameters()  \\\n",
    "                        if not any(nd in n for nd in no_decay)],  # Note only the parameters within bertflow.glow will be updated and the Transformer will be freezed during training.\n",
    "        \"weight_decay\": 0.01,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [p for n, p in bertflow.glow.named_parameters()  \\\n",
    "                        if any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "optimizer = AdamWeightDecayOptimizer(\n",
    "    params=optimizer_grouped_parameters, \n",
    "    lr=1e-3, \n",
    "    eps=1e-6,\n",
    ")\n",
    "num_epochs = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc731314-943f-4ee3-889c-1bd37ceea58d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34139872-f8d7-4ccf-816b-2656e7bc838c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2id_lst(str_label):\n",
    "    id_lst = []\n",
    "    for l in str_label.split(','):\n",
    "        id_lst.append(label2id[l])\n",
    "    return id_lst\n",
    "\n",
    "class PatentDataset(Dataset):\n",
    "    def __init__(self,df,labeled = True):\n",
    "        self.df = df\n",
    "        self.labeled = labeled\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        text = self.df.iloc[idx]['text'][3:]\n",
    "        label = str2id_lst(self.df.iloc[idx]['cpc_ids'])\n",
    "        \n",
    "        if self.labeled:\n",
    "            return text,label\n",
    "        else:\n",
    "            return text,None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd54a648-3731-4a71-94df-e405b05d1576",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PatentDataset(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d5037c0-9b01-4c1d-b26b-e4a3078f60b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    sents = [i[0] for i in data]\n",
    "    labels = [i[1] for i in data]\n",
    "    \n",
    "    data = tokenizer.batch_encode_plus(batch_text_or_text_pairs=sents,\n",
    "                                      truncation=True,\n",
    "                                      padding='longest',\n",
    "                                      max_length=512,\n",
    "                                      return_tensors='pt',\n",
    "                                      return_length=True,\n",
    "                                      )\n",
    "    input_ids = data['input_ids']\n",
    "    attention_mask = data['attention_mask']\n",
    "    token_type_ids = data['token_type_ids']\n",
    "    \n",
    "    batch_label = np.zeros((len(labels),len(id2label)))\n",
    "    for i,_label in enumerate(labels):\n",
    "        batch_label[i,_label]=1\n",
    "    \n",
    "    batch_label = torch.tensor(batch_label,dtype=torch.float32)\n",
    "    \n",
    "    return input_ids, attention_mask, token_type_ids, batch_label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ebbf43df-16cc-46a3-b9da-fbf871e9afd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset = train_dataset,\n",
    "                              batch_size = 32,\n",
    "                              collate_fn = collate_fn,\n",
    "                              shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcd4121-e2e7-4cc7-b606-b62c68b892ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72cab567-b02f-4460-90f0-fe192a5dee35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [03:56<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1/3,the training loss is -456.16820472478867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [03:58<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2/3,the training loss is -508.12320351600647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [03:57<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3/3,the training loss is -525.2040989398956\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0\n",
    "    bertflow = bertflow.cuda()\n",
    "    bertflow.train()\n",
    "    for iter,(input_ids, attention_mask, token_type_ids, batch_label) in enumerate(tqdm(train_dataloader)):\n",
    "        input_ids = input_ids.cuda()\n",
    "        attention_mask = attention_mask.cuda()\n",
    "        token_type_ids = token_type_ids.cuda()\n",
    "        z, loss = bertflow(input_ids, attention_mask, return_loss=True)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.detach().item()\n",
    "    \n",
    "    print(f'epoch:{epoch+1}/{num_epochs},the training loss is {train_loss}')\n",
    "\n",
    "bertflow.save_pretrained('output')  # Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c068c79e-edbd-49a6-b344-1d7793e0ae22",
   "metadata": {},
   "outputs": [],
   "source": [
    "bertflow = TransformerGlow.from_pretrained('output')  # Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f905f7cd-f93b-466e-821c-c132c6e4241f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18244b80-d3cb-4dc2-8385-cd8ea83b12ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a93185-099c-4a55-b05a-67747d9e4d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97278a8e-fec0-4f28-9627-bde4f1ad4773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6307bdde-aad0-48c2-a0ba-8cce6b3d2438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b378dfde-3d67-4c93-945f-9de363e5bb3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244e30dc-ae38-4428-bac1-3cddfc402687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb0b0f62-d2b7-4309-a547-fbb347521816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# patentModel.load_state_dict(torch.load('ckpt/001/best_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afcf1ae0-6214-487f-aed1-cfdb63b2e6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(patentModel.state_dict(), 'ckpt/001/best_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}